{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages for data set preprocessing, feature engineering, and model training\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "import numpy as np\n",
    "import xgboost, numpy, textblob, string\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Combine all data into one .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine five categories into five .csv files respetively by using for-loop\n",
    "root_path = r'./datasets_coursework1/bbc/'\n",
    "for root, paths, _ in os.walk(root_path, topdown=False):\n",
    "    for path in paths:\n",
    "        files = os.listdir(root_path + path)\n",
    "        title_list = []\n",
    "        data = pd.DataFrame()\n",
    "        content_list = []\n",
    "        for file in files:\n",
    "            position = root_path + path + '/' + file\n",
    "            with open(position,'r', encoding=\"ISO-8859-1\") as f:\n",
    "                content = f.readlines()\n",
    "                content.remove('\\n')\n",
    "                title_list.append(content[0].strip('\\n'))\n",
    "                content1 = [i.strip('\\n') for i in content[1:]]\n",
    "                content_list.append(content1)\n",
    "\n",
    "        data['title'] = pd.Series(title_list)\n",
    "        data['content'] = pd.Series(content_list)\n",
    "        data['label'] = path\n",
    "        csv_path = './part2_content/' + path + '.csv'\n",
    "        data.to_csv('./part2_content/' + path + '.csv',header=True,index=False,encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510, 3)\n",
      "(896, 3)\n",
      "(1313, 3)\n",
      "(1824, 3)\n",
      "(2225, 3)\n"
     ]
    }
   ],
   "source": [
    "# Combine 5 individual files into an entire .csv file, which is bbc_news.csv\n",
    "data1 = pd.read_csv('./part2_content/business.csv')\n",
    "print(data1.shape)\n",
    "data2 = pd.read_csv('./part2_content/entertainment.csv')\n",
    "data3 = pd.read_csv('./part2_content/politics.csv')\n",
    "data4 = pd.read_csv('./part2_content/sport.csv')\n",
    "data5 = pd.read_csv('./part2_content/tech.csv')\n",
    "data1 = data1.append(data2,ignore_index=True)\n",
    "print(data1.shape)\n",
    "data1 = data1.append(data3,ignore_index=True)\n",
    "print(data1.shape)\n",
    "data1 = data1.append(data4,ignore_index=True)\n",
    "print(data1.shape)\n",
    "data1 = data1.append(data5,ignore_index=True)\n",
    "print(data1.shape)\n",
    "data1.to_csv('./part2_content/bbc_news.csv',header=True,index=False,encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>UK economy facing 'major risks'</td>\n",
       "      <td>['The UK manufacturing sector will continue to...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Aids and climate top Davos agenda</td>\n",
       "      <td>['Climate change and the fight against Aids ar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Asian quake hits European shares</td>\n",
       "      <td>[\"Shares in Europe's leading reinsurers and tr...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>India power shares jump on debut</td>\n",
       "      <td>[\"Shares in India's largest power producer, Na...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Lacroix label bought by US firm</td>\n",
       "      <td>['Luxury goods group LVMH has sold its loss-ma...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  \\\n",
       "0    UK economy facing 'major risks'   \n",
       "1  Aids and climate top Davos agenda   \n",
       "2   Asian quake hits European shares   \n",
       "3   India power shares jump on debut   \n",
       "4    Lacroix label bought by US firm   \n",
       "\n",
       "                                             content     label  \n",
       "0  ['The UK manufacturing sector will continue to...  business  \n",
       "1  ['Climate change and the fight against Aids ar...  business  \n",
       "2  [\"Shares in Europe's leading reinsurers and tr...  business  \n",
       "3  [\"Shares in India's largest power producer, Na...  business  \n",
       "4  ['Luxury goods group LVMH has sold its loss-ma...  business  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data of bbc_news\n",
    "bbc_news_data = pd.read_csv('./Part2_content/bbc_news.csv')\n",
    "bbc_news_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = pd.DataFrame()\n",
    "trainDF['text'] = bbc_news_data['content']\n",
    "trainDF['label'] = bbc_news_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Split data into train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train set and test set\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(trainDF['text'], trainDF['label'],random_state=4235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319          business\n",
       "732     entertainment\n",
       "385          business\n",
       "1454            sport\n",
       "583     entertainment\n",
       "            ...      \n",
       "832     entertainment\n",
       "1904             tech\n",
       "1281         politics\n",
       "736     entertainment\n",
       "232          business\n",
       "Name: label, Length: 1668, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels 'business', 'entertainment', 'politics', 'sport', and 'tech' as 0, 1, 2, 3, 4, 5\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "test_y = encoder.fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Count Vector as Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='\\\\w{1,}', tokenizer=None,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a CountVectorizer object\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(trainDF['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use count vector to transform train set and test set\n",
    "xtrain_count = count_vect.transform(train_x)\n",
    "xtest_count = count_vect.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 TF-IDF as Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(trainDF['text'])\n",
    "xtrain_tfidf = tfidf_vect.transform(train_x)\n",
    "xtest_tfidf = tfidf_vect.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-gram tf-idf\n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(trainDF['text'])\n",
    "xtrain_tfidf_ngram = tfidf_vect_ngram.transform(train_x)\n",
    "xtest_tfidf_ngram = tfidf_vect_ngram.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qinliu/AI/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "# Character(Part of Speech) tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(trainDF['text'])\n",
    "xtrain_tfidf_ngram_chars = tfidf_vect_ngram_chars.transform(train_x)\n",
    "xtest_tfidf_ngram_chars = tfidf_vect_ngram_chars.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Word-embedding Vector as Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the pre-trained word-embedding vectors\n",
    "embeddings_index = {}\n",
    "for i, line in enumerate(open('./Part2_content/wiki-news-300d-1M.vec', encoding='UTF-8')):\n",
    "    values = line.split()\n",
    "    embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tokenizer\n",
    "token = text.Tokenizer()\n",
    "token.fit_on_texts(trainDF['text'])\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text to sequence of tokens and pad them to ensure equal length vectors\n",
    "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=70)\n",
    "test_seq_x = sequence.pad_sequences(token.texts_to_sequences(test_x), maxlen=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create token-embedding mapping\n",
    "embedding_matrix = numpy.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF['char_count'] = trainDF['text'].apply(len)\n",
    "trainDF['word_count'] = trainDF['text'].apply(lambda x: len(x.split()))\n",
    "trainDF['word_density'] = trainDF['char_count'] / (trainDF['word_count']+1)\n",
    "trainDF['punctuation_count'] = trainDF['text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation)))\n",
    "trainDF['title_word_count'] = trainDF['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "trainDF['upper_case_word_count'] = trainDF['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_family = {\n",
    "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "    'adj' :  ['JJ','JJR','JJS'],\n",
    "    'adv' : ['RB','RBR','RBS','WRB']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check and get the Character tag count of a words in a given sentence\n",
    "def check_pos_tag(x, flag):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        wiki = textblob.TextBlob(x)\n",
    "        for tup in wiki.tags:\n",
    "            ppo = list(tup)[1]\n",
    "            if ppo in pos_family[flag]:\n",
    "                cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF['noun_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'noun'))\n",
    "trainDF['verb_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'verb'))\n",
    "trainDF['adj_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'adj'))\n",
    "trainDF['adv_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'adv'))\n",
    "trainDF['pron_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'pron'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF[100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a LDA Model\n",
    "lda_model = decomposition.LatentDirichletAllocation(n_components=20, learning_method='online', max_iter=20)\n",
    "X_topics = lda_model.fit_transform(xtrain_count)\n",
    "topic_word = lda_model.components_\n",
    "vocab = count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_test, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "\n",
    "    # predict the labels on testation dataset\n",
    "    predictions = classifier.predict(feature_vector_test)\n",
    "\n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    return metrics.accuracy_score(test_y,predictions),\n",
    "metrics.classification_report(test_y,predictions,target_names=['business','entertainment','politics','sport','tech'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "accuracy,classification_report = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xtest_count)\n",
    "print(\"NB, Count Vectors: \", accuracy)\n",
    "print(\"NB, Count Vectors: \", classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy,classification_report = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xtest_tfidf)\n",
    "print(\"NB, WordLevel TF-IDF: \", accuracy)\n",
    "print(\"NB, WordLevel TF-IDF: \", classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy,classification_report = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xtest_tfidf_ngram)\n",
    "print(\"NB, N-Gram Vectors: \", accuracy)\n",
    "print(\"NB, N-Gram Vectors: \", classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "accuracy,classification_report = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xtest_tfidf_ngram_chars)\n",
    "print(\"NB, CharLevel Vectors: \", accuracy)\n",
    "print(\"NB, CharLevel Vectors: \", classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Classifier on Count Vectors\n",
    "accuracy,classification_report = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xtest_count)\n",
    "print(\"LR, Count Vectors: \", accuracy)\n",
    "print(\"LR, Count Vectors: \", classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, WordLevel TF-IDF:  0.9730700179533214\n",
      "LR, WordLevel TF-IDF:                 precision    recall  f1-score   support\n",
      "\n",
      "     business       0.96      0.96      0.96       141\n",
      "entertainment       0.99      0.96      0.97        97\n",
      "     politics       0.96      0.96      0.96       101\n",
      "        sport       0.99      1.00      1.00       125\n",
      "         tech       0.96      0.98      0.97        93\n",
      "\n",
      "     accuracy                           0.97       557\n",
      "    macro avg       0.97      0.97      0.97       557\n",
      " weighted avg       0.97      0.97      0.97       557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "accuracy,classification_report = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xtest_tfidf)\n",
    "print(\"LR, WordLevel TF-IDF: \", accuracy)\n",
    "print(\"LR, WordLevel TF-IDF: \", classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, N-Gram Vectors:  0.9443447037701975\n",
      "LR, N-Gram Vectors:                 precision    recall  f1-score   support\n",
      "\n",
      "     business       0.93      0.96      0.94       141\n",
      "entertainment       0.97      0.86      0.91        97\n",
      "     politics       0.96      0.96      0.96       101\n",
      "        sport       0.95      0.98      0.96       125\n",
      "         tech       0.93      0.96      0.94        93\n",
      "\n",
      "     accuracy                           0.94       557\n",
      "    macro avg       0.95      0.94      0.94       557\n",
      " weighted avg       0.94      0.94      0.94       557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy,classification_report = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xtest_tfidf_ngram)\n",
    "print(\"LR, N-Gram Vectors: \", accuracy)\n",
    "print(\"LR, N-Gram Vectors: \", classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, CharLevel Vectors:  0.9622980251346499\n",
      "LR, CharLevel Vectors:                 precision    recall  f1-score   support\n",
      "\n",
      "     business       0.96      0.98      0.97       141\n",
      "entertainment       1.00      0.89      0.94        97\n",
      "     politics       0.93      0.98      0.96       101\n",
      "        sport       0.98      0.99      0.98       125\n",
      "         tech       0.95      0.96      0.95        93\n",
      "\n",
      "     accuracy                           0.96       557\n",
      "    macro avg       0.96      0.96      0.96       557\n",
      " weighted avg       0.96      0.96      0.96       557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Character Level TF IDF Vectors\n",
    "accuracy,classification_report = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xtest_tfidf_ngram_chars)\n",
    "print(\"LR, CharLevel Vectors: \", accuracy)\n",
    "print(\"LR, CharLevel Vectors: \", classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, Count Vectors:  0.9622980251346499\n",
      "RF, Count Vectors:                 precision    recall  f1-score   support\n",
      "\n",
      "     business       0.95      0.98      0.96       141\n",
      "entertainment       0.99      0.93      0.96        97\n",
      "     politics       0.96      0.95      0.96       101\n",
      "        sport       0.97      1.00      0.98       125\n",
      "         tech       0.96      0.94      0.95        93\n",
      "\n",
      "     accuracy                           0.96       557\n",
      "    macro avg       0.96      0.96      0.96       557\n",
      " weighted avg       0.96      0.96      0.96       557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RF分类器\n",
    "# RF on Count Vectors\n",
    "accuracy,classification_report = train_model(ensemble.RandomForestClassifier(), xtrain_count, train_y, xtest_count)\n",
    "print(\"RF, Count Vectors: \", accuracy)\n",
    "print(\"RF, Count Vectors: \", classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, WordLevel TF-IDF:  0.9497307001795332\n",
      "RF, WordLevel TF-IDF:                 precision    recall  f1-score   support\n",
      "\n",
      "     business       0.92      0.96      0.94       141\n",
      "entertainment       0.98      0.89      0.93        97\n",
      "     politics       0.93      0.96      0.95       101\n",
      "        sport       0.97      0.99      0.98       125\n",
      "         tech       0.96      0.94      0.95        93\n",
      "\n",
      "     accuracy                           0.95       557\n",
      "    macro avg       0.95      0.95      0.95       557\n",
      " weighted avg       0.95      0.95      0.95       557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RF on Word Level TF IDF Vectors\n",
    "accuracy,classification_report = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y, xtest_tfidf)\n",
    "print(\"RF, WordLevel TF-IDF: \", accuracy)\n",
    "print(\"RF, WordLevel TF-IDF: \", classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qinliu/AI/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:55:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Xgb, Count Vectors:  0.9605026929982047\n",
      "Xgb, Count Vectors:                 precision    recall  f1-score   support\n",
      "\n",
      "     business       0.96      0.94      0.95       141\n",
      "entertainment       0.97      0.94      0.95        97\n",
      "     politics       0.94      0.97      0.96       101\n",
      "        sport       0.98      0.99      0.99       125\n",
      "         tech       0.95      0.96      0.95        93\n",
      "\n",
      "     accuracy                           0.96       557\n",
      "    macro avg       0.96      0.96      0.96       557\n",
      " weighted avg       0.96      0.96      0.96       557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extereme Gradient Boosting on Count Vectors\n",
    "accuracy,classification_report = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y, xtest_count.tocsc())\n",
    "print(\"Xgb, Count Vectors: \", accuracy)\n",
    "print(\"Xgb, Count Vectors: \", classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:55:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Xgb, WordLevel TF-IDF:  0.9497307001795332\n",
      "Xgb, WordLevel TF-IDF:                 precision    recall  f1-score   support\n",
      "\n",
      "     business       0.95      0.91      0.93       141\n",
      "entertainment       0.97      0.92      0.94        97\n",
      "     politics       0.90      0.97      0.93       101\n",
      "        sport       0.98      1.00      0.99       125\n",
      "         tech       0.96      0.95      0.95        93\n",
      "\n",
      "     accuracy                           0.95       557\n",
      "    macro avg       0.95      0.95      0.95       557\n",
      " weighted avg       0.95      0.95      0.95       557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
    "accuracy,classification_report = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y, xtest_tfidf.tocsc())\n",
    "print(\"Xgb, WordLevel TF-IDF: \", accuracy)\n",
    "print(\"Xgb, WordLevel TF-IDF: \", classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:55:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Xgb, CharLevel Vectors:  0.9533213644524237\n",
      "Xgb, CharLevel Vectors:                 precision    recall  f1-score   support\n",
      "\n",
      "     business       0.97      0.94      0.95       141\n",
      "entertainment       0.97      0.92      0.94        97\n",
      "     politics       0.91      0.98      0.94       101\n",
      "        sport       0.97      0.98      0.98       125\n",
      "         tech       0.95      0.95      0.95        93\n",
      "\n",
      "     accuracy                           0.95       557\n",
      "    macro avg       0.95      0.95      0.95       557\n",
      " weighted avg       0.95      0.95      0.95       557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extereme Gradient Boosting on Character Level TF IDF Vectors\n",
    "accuracy,classification_report = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram_chars.tocsc(), train_y, xtest_tfidf_ngram_chars.tocsc())\n",
    "print(\"Xgb, CharLevel Vectors: \", accuracy)\n",
    "print(\"Xgb, CharLevel Vectors: \", classification_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
